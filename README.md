# Airflow-пайплайн создания аналитической витрины
***********

# Цель
Создать витрину данных для аналитиков, которая будет содержать агрегированные метрики по карточкам товаром, популярным категориям и прочим.
***********

# Этапы проекта
1. Разработка Spark-приложения
2. Cоздание запросов о построении Greenplum - витрины
3. Автоматизация пайплайна обработки данных посредством создания DAGa
************

# Примененные технологии
- PySpark;
- Airflow;
- S3;
- PostgreSQL;
- Greenplum.
*************

# Инфраструктура
![Логотип проекта](images/изображение_2025-02-06_175139251.png)

В качестве технической инфраструктуры были использованы следующие инструменты:

1. Озеро данных на базе S3
2. Аналитическое хранилище на базе Greenplum
3. Оркестратор потоков данных - Airflow
4. Кластер распределенных вычислений Spark (Kubernetes)
5. GitLab для хранения исходного кода




